{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from hdbscan import HDBSCAN\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from six import StringIO\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from random import sample\n",
    "from random import seed\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed(24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load PSD expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.read_csv(\"geneexpression_labelled_region_ALLENcounts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr = pd.read_csv(\"Allen_labelledcounts_ALLGENES.csv\", chunksize=1024, iterator=True)\n",
    "rna2 = pd.concat(tfr, ignore_index=True)\n",
    "\n",
    "samples2= rna2['sample_name']\n",
    "labels2 = rna2['subclass_label']\n",
    "del rna2['sample_name']\n",
    "del rna2['subclass_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 20% of DG cells where selected on the all transcriptome dataframe due to memory issues. \n",
    "# We will select the same cells for PSD genes dataframe\n",
    "\n",
    "#matching_samples = samples1.isin(samples2)\n",
    "\n",
    "\n",
    "rna = rna[rna['Row.names'].isin(samples2)]\n",
    "rna.reset_index()\n",
    "#labels1= labels1[matching_samples]\n",
    "\n",
    "\n",
    "samples1= rna['Row.names']\n",
    "labels1 = rna['subclass_label']\n",
    "\n",
    "del rna['Row.names']\n",
    "del rna['subclass_label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSD genes only\n",
      "\n",
      "Number of genes:  4074\n",
      "Number of cells:  41506\n",
      "Number of labels:  41506\n",
      "\n",
      "Occurrences of classes\n",
      "CA1 : 12767\n",
      "CA1-ProS : 3355\n",
      "CA2 : 143\n",
      "CA3 : 1899\n",
      "CT SUB : 5414\n",
      "DG : 11664\n",
      "NP SUB : 1885\n",
      "SUB-ProS : 4379\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "All transcriptome\n",
      "\n",
      "Number of genes:  31053\n",
      "Number of cells:  41506\n",
      "Number of labels:  41506\n",
      "\n",
      "Occurrences of classes\n",
      "CA1 : 12767\n",
      "CA1-ProS : 3355\n",
      "CA2 : 143\n",
      "CA3 : 1899\n",
      "CT SUB : 5414\n",
      "DG : 11664\n",
      "NP SUB : 1885\n",
      "SUB-ProS : 4379\n"
     ]
    }
   ],
   "source": [
    "label= sorted(list(set(labels1)))\n",
    "\n",
    "print(\"PSD genes only\")\n",
    "print()\n",
    "print(\"Number of genes: \", len(rna.columns))\n",
    "print(\"Number of cells: \", len(rna))\n",
    "print(\"Number of labels: \", len(labels1))\n",
    "\n",
    " \n",
    "print()\n",
    "print(\"Occurrences of classes\")\n",
    "for lab in label:\n",
    "    print(lab + \" : \" + str(list(labels1.values).count(lab)))\n",
    "\n",
    "print()\n",
    "print(\"-------------------------------------\")\n",
    "print()\n",
    "print(\"All transcriptome\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Number of genes: \", len(rna2.columns))\n",
    "print(\"Number of cells: \", len(rna2))\n",
    "print(\"Number of labels: \", len(labels2))\n",
    "\n",
    "print()\n",
    " \n",
    "print(\"Occurrences of classes\")\n",
    "for lab in label:\n",
    "    print(lab + \" : \" + str(list(labels2.values).count(lab)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest models\n",
    "\n",
    "First, we use GridSearch on PSD dataset to look for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_l = list(range(5,13))\n",
    "n_estimators_l= [50,100,200]\n",
    "param_d = dict(max_depth=max_depth_l, n_estimators= n_estimators_l)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(rna, labels1,random_state=24,train_size=0.8)\n",
    "\n",
    "model_psd =  RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model_psd, param_d, cv=4)\n",
    "grid_fit=grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "score_pd=pd.DataFrame(grid_search.cv_results_)\n",
    "scores_2d=[]\n",
    "i=0\n",
    "for c in range(len(max_depth_l)):\n",
    "    scores_mat=[]\n",
    "    for g in range(len(n_estimators_l)):\n",
    "        mean_score= grid_search.cv_results_[\"mean_test_score\"][i]\n",
    "        scores_mat.append(mean_score)\n",
    "        i+=1\n",
    "    scores_2d.append(scores_mat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,10)) \n",
    "sns.heatmap(scores_2d,ax=ax, annot=True)\n",
    "ax.set_xticklabels(n_estimators_l)\n",
    "ax.set_yticklabels(max_depth_l)\n",
    "ax.set_xlabel(\"N estimators\")\n",
    "ax.set_ylabel(\"Max Depth\")\n",
    "fig.savefig('../MODELRF_params.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../MODELRF_params.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parametes n_estimators 200 max_depth 12\n",
    "\n",
    "### Random Forest model (PSD genes) with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_psd =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_psd.fit(X_train, y_train)\n",
    "y_pred_train = model_psd.predict(X_train)\n",
    "y_pred_test = model_psd.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(conf_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = pd.DataFrame(confusion_matrix_norm,index=label, columns=label)\n",
    "accuracy_test = accuracy_test.reindex(sorted(accuracy_test.columns), axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,10)) \n",
    "\n",
    "sns.heatmap(np.array(accuracy_test),ax=ax, annot=True, vmin=0, vmax=1, fmt='.4f', cmap=\"Oranges\", annot_kws={\"fontsize\":14})\n",
    "ax.set_xticklabels(label)\n",
    "ax.set_yticklabels(label)\n",
    "ax.set_xlabel(\"Predicted Class\")\n",
    "ax.set_ylabel(\"True Class\")\n",
    "fig.savefig('../MODELRFPSD_confussion_matrix_test.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_psd.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model_psd.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "\n",
    "\n",
    "\n",
    "#plt.hist(forest_importances)\n",
    "\n",
    "#print(forest_importances.median())\n",
    "print(forest_importances.sort_values(ascending=False)[0:20])\n",
    "forest_importances.sort_values(ascending=False).to_csv(\"../feats_importances_PSDGENES.csv\")\n",
    "psdmodel_importances= forest_importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Graph of cumulative feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdmodel_cumsum_importances=0\n",
    "psdmodel_cumsum=[]\n",
    "totaln= 1000\n",
    "#totaln= len(psdmodel_importances) \n",
    "\n",
    "for i in range(totaln):\n",
    "    psdmodel_cumsum_importances += psdmodel_importances[i]\n",
    "    psdmodel_cumsum.append(psdmodel_cumsum_importances)\n",
    "    \n",
    "fig, ax = plt.subplots( nrows=1, ncols=1 )  # create figure & 1 axis\n",
    "ax.plot(list(range(1,totaln+1)), psdmodel_cumsum, color=\"b\", label=\"Total\")\n",
    "#ax.plot(list(range(1,totaln+1)), lpsd_cumsum, color=\"g\", label=\"Genes from PSD\")\n",
    "#ax.plot(list(range(1,totaln+1)), lnopsd_cumsum, color=\"y\", label=\"non-PSD genes\" )\n",
    "#ax.legend()\n",
    "ax.set_xlabel(\"Number of genes\")\n",
    "ax.set_ylabel(\"Feature importance\")\n",
    "#fig.savefig('../importanceS_PSDGENES_1000genes.svg')   # save the figure to file\n",
    "#plt.close(fig) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of genes where the curve start to saturate is around 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model with whole transcriptome\n",
    "\n",
    "We will use the same parameters as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(rna2, labels2,random_state=24,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = pd.DataFrame(confusion_matrix_norm,index=label, columns=label)\n",
    "accuracy_test = accuracy_test.reindex(sorted(accuracy_test.columns), axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,10)) \n",
    "\n",
    "\n",
    "sns.heatmap(np.array(accuracy_test),ax=ax, annot=True, vmin=0, vmax=1, fmt='.4f', cmap=\"Oranges\", annot_kws={\"fontsize\":14} )\n",
    "ax.set_xticklabels(label)\n",
    "ax.set_yticklabels(label)\n",
    "ax.set_xlabel(\"Predicted Class\")\n",
    "ax.set_ylabel(\"True Class\")\n",
    "\n",
    "fig.savefig('../MODELRF_confussion_matrix_test_wholetransc.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_allgenes.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model_allgenes.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "\n",
    "\n",
    "#plt.hist(forest_importances)\n",
    "\n",
    "#print(forest_importances.median())\n",
    "forest_importances.sort_values(ascending=False).to_csv(\"../feats_moreimportancesRF_ALLGENES.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature importances (PSD and ALL TRANSCRIPTOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_psd = pd.read_csv(\"../feats_importances_PSDGENES.csv\")\n",
    "feature_importances_alltc= pd.read_csv(\"../feats_importances_ALLGENES.csv\")\n",
    "non_PSD_genes = list(set(feature_importances_psd['Unnamed: 0'].values) - set(feature_importances_alltc['Unnamed: 0'].values))\n",
    "feature_importances_nonPSD = feature_importances_alltc[feature_importances_alltc['Unnamed: 0'].isin(non_PSD_genes)].sort_values(by=\"0\",ascending=False).reset_index(drop=True)\n",
    "importances_allgenes_psd= feature_importances_psd[\"0\"]\n",
    "importances_allgenes_alltc= feature_importances_alltc[\"0\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest model with non-PSD genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_PSD_genes = list(set(list(rna2.columns)) - set(list(rna.columns)))\n",
    "\n",
    "#rand_nonpsd_genes = sample(non_PSD_genes, 4000)\n",
    "nonpsd_rand = rna2.loc[:,rna2.columns.isin(non_PSD_genes)]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(nonpsd_rand, labels2,random_state=24,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest models with subsets of genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model with 500 more important genes of the PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_importants = rna.loc[:,rna.columns.isin(feature_importances_psd[\"Unnamed: 0\"][0:500])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(psd_importants, labels1,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSD 1000 + important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_importants = rna.loc[:,rna.columns.isin(feature_importances_psd[\"Unnamed: 0\"][0:1000])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(psd_importants, labels1,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO-PSD RANDOM 4074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PSD_genes = list(set(list(rna2.columns)) - set(list(rna.columns)))\n",
    "\n",
    "rand_nonpsd_genes = sample(non_PSD_genes, 4074)\n",
    "\n",
    "nonpsd_rand = rna2.loc[:,rna2.columns.isin(rand_nonpsd_genes)]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(nonpsd_rand, labels2,random_state=24,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 1000 alltc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom1000_genes = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][-1000:])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(bottom1000_genes, labels2,random_state=24,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10000_genes = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][-10000:])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(bottom10000_genes, labels2,random_state=24,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom20000_genes = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][-20000:])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(bottom20000_genes, labels2,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom25000_genes = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][-25000:])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(bottom25000_genes, labels2,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL TRANSCRIPTOME 1000 + IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltc_importants = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(alltc_importants, labels2,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL TRANSCRIPTOME 500 + IMPORTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltc_importants = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][0:500])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(alltc_importants, labels2,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL TRANSCRIPTOME 100 + IMPORTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltc_importants = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][0:100])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(alltc_importants, labels2,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 ALL TRANSCRIPTOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltc_importants = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][0:10])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(alltc_importants, labels2,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSD  TOP 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_importants = rna.loc[:,rna.columns.isin(feature_importances_psd[\"Unnamed: 0\"][0:100])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(psd_importants, labels1,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSD TOP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_importants = rna.loc[:,rna.columns.isin(feature_importances_psd[\"Unnamed: 0\"][0:10])]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(psd_importants, labels1,random_state=24,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_allgenes =  RandomForestClassifier(n_estimators=200, max_depth=12, random_state=24)\n",
    "model_allgenes.fit(X_train, y_train)\n",
    "y_pred_train = model_allgenes.predict(X_train)\n",
    "y_pred_test = model_allgenes.predict(X_test)\n",
    "\n",
    "label = sorted(list(set(y_train)))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_mat_train = confusion_matrix(y_train, y_pred_train, labels= label)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test, labels= label)\n",
    "\n",
    "confusion_matrix_norm = conf_mat_test.astype('float') / conf_mat_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Train Set\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(conf_mat_train)\n",
    "print()\n",
    "print(\"Test Set\")\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "print(confusion_matrix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSD genes vs non-PSD genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 1000 PSD vs no-PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importants_1000 = feature_importances_alltc['Unnamed: 0'][0:1000]\n",
    "y = np.array([sum(rna.columns.isin(importants_1000)), 1000 - sum(rna.columns.isin(importants_1000))])\n",
    "mylabels = [\"PSD\", \"Non_PSD\"]\n",
    "\n",
    "fig, ax = plt.subplots( nrows=1, ncols=1 )  # create figure & 1 axis\n",
    "ax.pie(y, labels = mylabels)\n",
    "fig.savefig('PSDvsNonPSD_pie.svg')   # save the figure to file\n",
    "plt.show()\n",
    "plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topgenes= feature_importances_alltc[\"Unnamed: 0\"][:1000]\n",
    "\n",
    "psd_prots= pd.read_csv(\"../dani/Arxius/scrna/psd_proteins.txt\")\n",
    "psd_prots_l=list(psd_prots[\"Reference Proteome Distler PSDII & Reig-Viader (4301)\"].values)\n",
    "\n",
    "n_psd_genes_present = 4116\n",
    "total_genes = len(feature_importances_alltc)\n",
    "no_psd_genes = total_genes - n_psd_genes_present\n",
    "\n",
    "n_psdprots_important=0\n",
    "for val in topgenes:\n",
    "    if val in psd_prots_l:\n",
    "        n_psdprots_important+=1\n",
    "n_nopsdgenes_important= len(topgenes) - n_psdprots_important\n",
    "n_psdprots_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum_importances=0\n",
    "l_cumsum=[]\n",
    "cumsum_psdimportances=0\n",
    "cumsum_nopsdimportances=0\n",
    "lpsd_cumsum=[]\n",
    "lnopsd_cumsum=[]\n",
    "totaln= 10000\n",
    "#totaln= len(feature_importances) \n",
    "\n",
    "for i in range(totaln):\n",
    "    cumsum_importances += feature_importances_alltc[\"0\"][i]\n",
    "    genename= feature_importances_alltc[\"Unnamed: 0\"][i]\n",
    "    \n",
    "    if genename in psd_prots_l:\n",
    "        cumsum_psdimportances+= feature_importances_alltc[\"0\"][i]\n",
    "    else:\n",
    "        cumsum_nopsdimportances+= feature_importances_alltc[\"0\"][i]\n",
    "        \n",
    "    l_cumsum.append(cumsum_importances)\n",
    "    lpsd_cumsum.append(cumsum_psdimportances)\n",
    "    lnopsd_cumsum.append(cumsum_nopsdimportances)\n",
    "\n",
    "fig, ax = plt.subplots( nrows=1, ncols=1 )  # create figure & 1 axis\n",
    "ax.plot(list(range(1,totaln+1)), l_cumsum, color=\"b\", label=\"Total\")\n",
    "#ax.plot(list(range(1,totaln+1)), lpsd_cumsum, color=\"g\", label=\"Genes from PSD\")\n",
    "#ax.plot(list(range(1,totaln+1)), lnopsd_cumsum, color=\"y\", label=\"non-PSD genes\" )\n",
    "#ax.legend()\n",
    "ax.set_xlabel(\"Number of genes\")\n",
    "ax.set_ylabel(\"Feature importance\")\n",
    "fig.savefig('../feats_importancesRF_ALLGENES_only2000genes.svg')   # save the figure to file\n",
    "#plt.close(fig) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indica que el número óptimo de genes para definir las diferentes regiones son 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"suma importancias primeros 750 genes (1%)\")\n",
    "print(sum(importances_allgenes_alltc[0:30000]))\n",
    "print(\"suma importancias resto de genes (1%)\")\n",
    "print(sum(importances_allgenes_alltc[30000:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared tests\n",
    "\n",
    "### Chi Squared PSD vs noPSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[518, 3556], [482, 26497]]\n",
      "dof=1\n",
      "[[  131.19505362  3942.80494638]\n",
      " [  868.80494638 26110.19505362]]\n",
      "probability=0.950, critical=3.841, stat=1352.809\n",
      "significance=0.050, p=0.0000000000000000000000000000000000000000\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "psd_genes = feature_importances_psd[\"Unnamed: 0\"]\n",
    "\n",
    "num_psdgenes_present = len(psd_genes)\n",
    "num_psdgenes_important= len(list(psd_genes[psd_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "\n",
    "num_psdgenes_not_important= num_psdgenes_present - num_psdgenes_important\n",
    "\n",
    "rest_important = 1000 - num_psdgenes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_psdgenes_not_important)\n",
    "\n",
    "table = [[num_psdgenes_important, num_psdgenes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.40f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n",
    "    \n",
    "    \n",
    "#final_table= [table[0][0],expected[0][0], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[518, 3556], [482, 26497]]\n",
      "8.00788218381416 1.3022186923268363e-197\n"
     ]
    }
   ],
   "source": [
    "psd_genes = feature_importances_psd[\"Unnamed: 0\"]\n",
    "\n",
    "num_psdgenes_present = len(psd_genes)\n",
    "num_psdgenes_important= len(list(psd_genes[psd_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "\n",
    "num_psdgenes_not_important= num_psdgenes_present - num_psdgenes_important\n",
    "\n",
    "rest_important = 1000 - num_psdgenes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_psdgenes_not_important)\n",
    "\n",
    "table = [[num_psdgenes_important, num_psdgenes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes PSD enriched and MAGUK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customset_prots= pd.read_csv(\"../DATASETS_PSD_EN_MAGUK.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSD enriched: Chi square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_enriched= customset_prots[\"PSD_Enriched\"].dropna()\n",
    "\n",
    "\n",
    "num_psdenriched_present = len(list(psd_enriched[psd_enriched.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_psdenriched_important= len(list(psd_enriched[psd_enriched.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_psdenriched_not_important= num_psdenriched_present - num_psdenriched_important\n",
    "\n",
    "rest_important = 1000 - num_psdenriched_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_psdenriched_not_important)\n",
    "\n",
    "table = [[num_psdenriched_important, num_psdenriched_not_important],[rest_important, rest_not_important ]]\n",
    "\n",
    "print(table)\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.23f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119, 628], [881, 29425]]\n",
      "6.328894857465098 2.1593296570667785e-48\n"
     ]
    }
   ],
   "source": [
    "psd_enriched= customset_prots[\"PSD_Enriched\"].dropna()\n",
    "\n",
    "\n",
    "num_psdenriched_present = len(list(psd_enriched[psd_enriched.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_psdenriched_important= len(list(psd_enriched[psd_enriched.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_psdenriched_not_important= num_psdenriched_present - num_psdenriched_important\n",
    "\n",
    "rest_important = 1000 - num_psdenriched_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_psdenriched_not_important)\n",
    "\n",
    "table = [[num_psdenriched_important, num_psdenriched_not_important],[rest_important, rest_not_important ]]\n",
    "\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAGUK complex: Chi Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maguk_prots= customset_prots[\"MAGUK COMPLEX\"].dropna()\n",
    "\n",
    "num_maguk_genes_present = len(list(maguk_prots[maguk_prots.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_maguk_genes_important= len(list(maguk_prots[maguk_prots.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_maguk_genes_not_important= num_maguk_genes_present - num_maguk_genes_important\n",
    "\n",
    "rest_important = 1000 - num_maguk_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_maguk_genes_not_important)\n",
    "\n",
    "table = [[num_maguk_genes_important, num_maguk_genes_not_important],[rest_important, rest_not_important ]]\n",
    "\n",
    "print(table)\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.23f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59, 170], [941, 29883]]\n",
      "11.021422766768769 3.273209330945839e-36\n"
     ]
    }
   ],
   "source": [
    "maguk_prots= customset_prots[\"MAGUK COMPLEX\"].dropna()\n",
    "\n",
    "num_maguk_genes_present = len(list(maguk_prots[maguk_prots.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_maguk_genes_important= len(list(maguk_prots[maguk_prots.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_maguk_genes_not_important= num_maguk_genes_present - num_maguk_genes_important\n",
    "\n",
    "rest_important = 1000 - num_maguk_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_maguk_genes_not_important)\n",
    "\n",
    "table = [[num_maguk_genes_important, num_maguk_genes_not_important],[rest_important, rest_not_important ]]\n",
    "\n",
    "print(table)\n",
    "\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-coding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28, 8500], [972, 21553]]\n",
      "0.07304333091261196 1.0\n"
     ]
    }
   ],
   "source": [
    "NC_genes = pd.Series(list(set(pd.read_csv('non_coding_genes.txt', sep=',', header=0)[\"x\"])))\n",
    "num_NC_genes_present = len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_NC_genes_important= len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_NC_genes_not_important= num_NC_genes_present - num_NC_genes_important\n",
    "\n",
    "rest_important = 1000 - num_NC_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_NC_genes_not_important)\n",
    "\n",
    "table = [[num_NC_genes_important, num_NC_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28, 8500], [972, 21553]]\n",
      "dof=1\n",
      "[[  274.62725019  8253.37274981]\n",
      " [  725.37274981 21799.62725019]]\n",
      "probability=0.950, critical=3.841, stat=314.217\n",
      "significance=0.050, p=0.00000000000000000000000\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "NC_genes = pd.Series(list(set(pd.read_csv('non_coding_genes.txt', sep=',', header=0)[\"x\"])))\n",
    "num_NC_genes_present = len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_NC_genes_important= len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_NC_genes_not_important= num_NC_genes_present - num_NC_genes_important\n",
    "\n",
    "rest_important = 1000 - num_NC_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_NC_genes_not_important)\n",
    "\n",
    "table = [[num_NC_genes_important, num_NC_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.23f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC_genes = pd.Series(list(set(pd.read_csv('coding_genes.txt', sep=',', header=0)[\"x\"])))\n",
    "num_NC_genes_present = len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_NC_genes_important= len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_NC_genes_not_important= num_NC_genes_present - num_NC_genes_important\n",
    "\n",
    "rest_important = 1000 - num_NC_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_NC_genes_not_important)\n",
    "\n",
    "table = [[num_NC_genes_important, num_NC_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.23f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[952, 19998], [48, 10055]]\n",
      "9.972205553888722 6.535309273689526e-107\n"
     ]
    }
   ],
   "source": [
    "NC_genes = pd.Series(list(set(pd.read_csv('coding_genes.txt', sep=',', header=0)[\"x\"])))\n",
    "num_NC_genes_present = len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_NC_genes_important= len(list(NC_genes[NC_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_NC_genes_not_important= num_NC_genes_present - num_NC_genes_important\n",
    "\n",
    "rest_important = 1000 - num_NC_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_NC_genes_not_important)\n",
    "\n",
    "table = [[num_NC_genes_important, num_NC_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SYNGO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC_genes = pd.Series(list(set(pd.read_csv('SYNGO_GENES.txt', sep='\\t', header=0)[\"hgnc_symbol\"])))\n",
    "\n",
    "\n",
    "\n",
    "num_NC_genes_present = len(list(NC_genes[NC_genes.isin(x.upper() for x in feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_NC_genes_important= len(list(NC_genes[NC_genes.isin(x.upper() for x in feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_NC_genes_not_important= num_NC_genes_present - num_NC_genes_important\n",
    "\n",
    "rest_important = 1000 - num_NC_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_NC_genes_not_important)\n",
    "\n",
    "table = [[num_NC_genes_important, num_NC_genes_not_important],[rest_important, rest_not_important ]]\n",
    "\n",
    "print(table)\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.23f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[292, 913], [708, 29140]]\n",
      "13.163408642273254 1.642174971725796e-177\n"
     ]
    }
   ],
   "source": [
    "NC_genes = pd.Series(list(set(pd.read_csv('SYNGO_GENES.txt', sep='\\t', header=0)[\"hgnc_symbol\"])))\n",
    "\n",
    "num_NC_genes_present = len(list(NC_genes[NC_genes.isin(x.upper() for x in feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_NC_genes_important= len(list(NC_genes[NC_genes.isin(x.upper() for x in feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_NC_genes_not_important= num_NC_genes_present - num_NC_genes_important\n",
    "\n",
    "rest_important = 1000 - num_NC_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_NC_genes_not_important)\n",
    "\n",
    "table = [[num_NC_genes_important, num_NC_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Squared for GO terms\n",
    "\n",
    "### GO:0007155 Cell Adhesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0007155.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0007158 Neuron cell-cell adhesion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0007158.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0045785 Positive regulation of cell adhesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0045785.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0001764 Neuron Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0001764.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0021954 Central nervous system neuron development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0021954.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:1990138 Neuron projection extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO1990138.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0030154 Cell Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0030154.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0008134 transcription factor binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0008134.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0010467 gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0010467.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0010468 regulation of gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0010468.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO:0061621 canonical glycolysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_genes = pd.Series(list(set(pd.read_csv('GO0061621.txt', sep='\\t', header=0)[\"SYMBOL\"])))\n",
    "\n",
    "num_GO_genes_present = len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"])].values))\n",
    "num_GO_genes_important= len(list(GO_genes[GO_genes.isin(feature_importances_alltc[\"Unnamed: 0\"][0:1000])].values))\n",
    "num_GO_genes_not_important= num_GO_genes_present - num_GO_genes_important\n",
    "\n",
    "rest_important = 1000 - num_GO_genes_important\n",
    "rest_not_important = len(feature_importances_alltc) - (1000 + num_GO_genes_not_important)\n",
    "\n",
    "table = [[num_GO_genes_important, num_GO_genes_not_important],[rest_important, rest_not_important ]]\n",
    "print(table)\n",
    "stat, p = fisher_exact(table, alternative =\"greater\")\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(set(list(rna2.columns)) - set(list(rna.columns)))))\n",
    "label = sorted(list(set(labels1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP PSD genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist= 0.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_psd_a = pd.DataFrame(rna_umap.fit_transform(rna), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_psd_a, hue=labels1.values, hue_order=label,alpha=.1, linewidth=0, s=1)\n",
    "\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_PSD_all.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=24)\n",
    "\n",
    "X_resampled, y_resampled = rus.fit_resample(rna, labels1)\n",
    "\n",
    "print(X_resampled)\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist= 0.01)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_psd_a = pd.DataFrame(rna_umap.fit_transform(X_resampled), columns = ['UMAP1','UMAP2'])\n",
    "#print(label)\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "#sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_psd_a, hue=y_resampled, hue_order=label,alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "#sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "fig, ax = plt.subplots()\n",
    "embedding_psd_a.plot(kind='scatter', x='UMAP1', y='UMAP2', c= pd.factorize(y_resampled.values)[0].astype(np.uint16), cmap='Accent_r', figsize=(16,10), ax=ax)\n",
    "ax.legend(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN and Kmeans for prediction from UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_umap_psd_all = HDBSCAN.hdbscan(min_samples=10, min_cluster_size=500).fit_predict(embedding_psd_a)\n",
    "#dbscan= HDBSCAN(min_cluster_size=100, min_samples=100)\n",
    "\n",
    "\n",
    "#Entrenamos y predecimos\n",
    "#___________________________________________________________\n",
    "#preds = dbscan.fit_predict(embedding_psd_a)\n",
    "\n",
    "\n",
    "#Métricas de Clustering\n",
    "#___________________________________________________________\n",
    "\n",
    "\n",
    "#silhouette_score(embedding_psd_a, preds)\n",
    "\n",
    "#calinski_harabasz_score(embedding_psd_a, preds)\n",
    "\n",
    "#Hacemos un plot de los resultados\n",
    "\n",
    "#embedding_psd_a.plot(kind='scatter', x='UMAP1', y='UMAP2', c=rna['Rab6a'], cmap = 'magma',figsize=(16,10))\n",
    "embedding_psd_a.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centeroidnp(embed, labels, categories):\n",
    "    centroids_final = []\n",
    "    arr = embed[['UMAP1', 'UMAP2']].to_numpy()\n",
    "    for cat in categories:\n",
    "        indices = [i for i, x in enumerate(labels) if x == cat]\n",
    "        subset = arr[indices]\n",
    "        length, dim = subset.shape\n",
    "        centroids_final.append(np.array([np.sum(subset[:, i])/length for i in range(dim)]))\n",
    "    return np.array(centroids_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_centroids = centeroidnp(X_resampled, y_resampled, label)\n",
    "centroids= KMeans(n_clusters=8, init=start_centroids, n_init=1)\n",
    "\n",
    "preds= centroids.fit_predict(embedding_psd_a)\n",
    "embedding_psd_a.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP for PSD genes importants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_importants = rna.loc[:,rna.columns.isin(feature_importances_psd[\"Unnamed: 0\"][0:100])]\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_psd_i = pd.DataFrame(rna_umap.fit_transform(psd_importants), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_psd_i,\n",
    "                hue=labels1.values, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_PSD_importants_100.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_umap_psd_all = HDBSCAN.hdbscan(min_samples=10, min_cluster_size=500).fit_predict(embedding_psd_a)\n",
    "dbscan= HDBSCAN(min_cluster_size=100, min_samples=100)\n",
    "\n",
    "\n",
    "#Entrenamos y predecimos\n",
    "#___________________________________________________________\n",
    "preds = dbscan.fit_predict(embedding_psd_i)\n",
    "\n",
    "\n",
    "#Métricas de Clustering\n",
    "#___________________________________________________________\n",
    "\n",
    "\n",
    "#silhouette_score(embedding_psd_a, preds)\n",
    "\n",
    "#calinski_harabasz_score(embedding_psd_a, preds)\n",
    "\n",
    "#Hacemos un plot de los resultados\n",
    "\n",
    "embedding_psd_i.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_centroids = centeroidnp(embedding_psd_i, labels1, label[:2]+label[3:])\n",
    "centroids= KMeans(n_clusters=7, init=start_centroids, n_init=1)\n",
    "\n",
    "preds= centroids.fit_predict(embedding_psd_i)\n",
    "embedding_psd_i.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP random PSD genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_psd_genes = sample(list(rna.columns), 100)\n",
    "random100 = rna.loc[:,rna.columns.isin(rand_psd_genes)]\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_psd_r = pd.DataFrame(rna_umap.fit_transform(random100), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_psd_r,\n",
    "                hue=labels1.values, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_PSD_rand100.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_umap_psd_all = HDBSCAN.hdbscan(min_samples=10, min_cluster_size=500).fit_predict(embedding_psd_a)\n",
    "dbscan= HDBSCAN(min_cluster_size=100, min_samples=100)\n",
    "\n",
    "\n",
    "#Entrenamos y predecimos\n",
    "#___________________________________________________________\n",
    "preds = dbscan.fit_predict(embedding_psd_r)\n",
    "\n",
    "\n",
    "#Métricas de Clustering\n",
    "#___________________________________________________________\n",
    "\n",
    "#silhouette_score(embedding_psd_a, preds)\n",
    "\n",
    "#calinski_harabasz_score(embedding_psd_a, preds)\n",
    "\n",
    "#Hacemos un plot de los resultados\n",
    "embedding_psd_r.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_centroids = centeroidnp(embedding_psd_r, labels1, label[:2]+label[3:])\n",
    "centroids= KMeans(n_clusters=7, init=start_centroids, n_init=1)\n",
    "\n",
    "preds= centroids.fit_predict(embedding_psd_r)\n",
    "embedding_psd_r.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAPs for ALL transcriptome and non-PSD\n",
    "\n",
    "### All genes from transcriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_alltc_a = pd.DataFrame(rna_umap.fit_transform(rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][0:30000])]), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_alltc_a,\n",
    "                hue=labels2.values, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_ALLTC_top30000.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP 1000 less importants (bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_alltc_a = pd.DataFrame(rna_umap.fit_transform(rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][-1000:])]), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_alltc_a,\n",
    "                hue=labels2.values, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_ALLTC_bottom1000.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan= HDBSCAN(min_cluster_size=100, min_samples=100)\n",
    "\n",
    "\n",
    "#Entrenamos y predecimos\n",
    "#___________________________________________________________\n",
    "preds = dbscan.fit_predict(embedding_alltc_a)\n",
    "\n",
    "\n",
    "#Métricas de Clustering\n",
    "#___________________________________________________________\n",
    "\n",
    "#silhouette_score(embedding_psd_a, preds)\n",
    "\n",
    "#calinski_harabasz_score(embedding_psd_a, preds)\n",
    "\n",
    "#Hacemos un plot de los resultados\n",
    "embedding_alltc_a.plot(kind='scatter', x='UMAP1', y='UMAP2', c=preds, cmap='Accent_r', figsize=(16,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP ALLTC importants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alltc_importants = rna2.loc[:,rna2.columns.isin(feature_importances_alltc[\"Unnamed: 0\"][0:100])]\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_alltc_i = pd.DataFrame(rna_umap.fit_transform(alltc_importants), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_alltc_i,\n",
    "                hue=labels2.values, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "sns_plot.figure.savefig('umap_ALLTC_top100.svg', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP non-PSD all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_nonpsd_genes = sample(non_PSD_genes, 4000)\n",
    "\n",
    "nonpsd_rand = rna2.loc[:,rna2.columns.isin(non_PSD_genes)]\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_nonpsd_r = pd.DataFrame(rna_umap.fit_transform(nonpsd_rand), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_nonpsd_r,\n",
    "                hue=labels2, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_nonPSD_all_20220718.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP non-PSD 4074 random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_nonpsd_genes = sample(non_PSD_genes, 4074)\n",
    "\n",
    "nonpsd_rand = rna2.loc[:,rna2.columns.isin(rand_nonpsd_genes)]\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_nonpsd_r = pd.DataFrame(rna_umap.fit_transform(nonpsd_rand), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_nonpsd_r,\n",
    "                hue=labels2, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_nonPSD_rand4074.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP non-PSD top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpsd_rand = rna2.loc[:,rna2.columns.isin(feature_importances_nonPSD[\"Unnamed: 0\"][0:100])]\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=15, min_dist=.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_nonpsd_r = pd.DataFrame(rna_umap.fit_transform(nonpsd_rand), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_nonpsd_r,\n",
    "                hue=labels2.values, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_nonPSD_top100.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP nonPSD random 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_nonpsd_genes = sample(non_PSD_genes, 100)\n",
    "nonpsd_rand = rna2.loc[:,rna2.columns.isin(rand_nonpsd_genes)]\n",
    "\n",
    "\n",
    "rna_umap = UMAP(random_state=24, n_neighbors=30, min_dist=.1)\n",
    "\n",
    "# Fit UMAP and extract latent vars 1-2\n",
    "embedding_nonpsd_r = pd.DataFrame(rna_umap.fit_transform(nonpsd_rand), columns = ['UMAP1','UMAP2'])\n",
    "\n",
    "# Produce sns.scatterplot and pass metadata.subclasses as color\n",
    "sns_plot = sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_nonpsd_r,\n",
    "                hue=labels2, hue_order=label,\n",
    "                alpha=.1, linewidth=0, s=1)\n",
    "# Adjust legend\n",
    "sns_plot.legend(loc='center left', bbox_to_anchor=(1, .5))\n",
    "# Save PNG\n",
    "plt.show()\n",
    "sns_plot.figure.savefig('umap_nonPSD_100.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
